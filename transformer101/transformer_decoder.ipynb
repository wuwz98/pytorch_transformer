{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 训练一个电子鹦鹉"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from tqdm.auto import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:35:21.572450Z",
     "start_time": "2024-07-25T15:35:19.414187Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total characters: 604898\n"
     ]
    }
   ],
   "source": [
    "with open('trainingdata/三国演义.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    print(f\"total characters: {len(text)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:40:31.399912Z",
     "start_time": "2024-07-25T15:40:31.381030Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型定义"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# hard coded! 人工构建的位置向量\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, max_len=4096):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, embed_size)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * -(math.log(10000.0) / embed_size))\n",
    "        \n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1)].detach()\n",
    "\n",
    "# 多头注意力机制实现\n",
    "# B batchsize\n",
    "# T seq len\n",
    "# C hidden_size(全局)\n",
    "# h head\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # 进行参数校验，即head必须能够整除hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert (self.head_dim * heads == embed_size), \"Embedding size needs to be divisible by heads\"\n",
    "        \n",
    "        # 初始化Q, K, V矩阵作为可学习的参数\n",
    "        # 在多头自注意力机制中我们还需要一个线性层 [h1, h2, h3, h4] --线性层--> [hidden_state]\n",
    "        self.values = nn.Linear(self.embed_size, self.embed_size, bias=False)\n",
    "        self.keys = nn.Linear(self.embed_size, self.embed_size, bias=False)\n",
    "        self.queries = nn.Linear(self.embed_size, self.embed_size, bias=False)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    # 正常的输入：[T, C]，\n",
    "    # batch下：[B, T, C]\n",
    "    def forward(self, value, key, query, mask):\n",
    "        B = query.shape[0]\n",
    "        # self-attention 情况下value, key, query长度是一致的，cross-attention则不一致，这里做了兼容（不过这是个decoder -_-）\n",
    "        value_len, key_len, query_len = value.shape[1], key.shape[1], query.shape[1]\n",
    "\n",
    "        # [B, T, C] -> [B, T, h, C/h] 多头自注意力，这里不涉及数据移动，只修改strides\n",
    "        value = self.values(value).view(B, value_len, self.heads, self.head_dim)\n",
    "        key = self.keys(key).view(B, key_len, self.heads, self.head_dim)\n",
    "        query = self.queries(query).view(B, query_len, self.heads, self.head_dim)\n",
    "        \n",
    "        # [T, C] * [C, T] -> [T, T] attention\n",
    "        # [B, T, C] * [B, C, T] -> [B, T, T] batch\n",
    "        # [B, T, h, C/h] -> [B, h, T, C/h]\n",
    "        # [B, h, T, C/h] * [B, h, C/h, T] -> [B, h, T, T] multi-head attention\n",
    "        queries_t = query.transpose(1,2)\n",
    "        keys_t = key.transpose(1, 2).transpose(2, 3)\n",
    "        values_t = value.transpose(1, 2)\n",
    "        \n",
    "        # attention: [B, h, T, T]\n",
    "        energy = torch.matmul(queries_t, keys_t)\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 1, float(\"-inf\"))\n",
    "        score = energy / (self.embed_size ** (1 / 2))\n",
    "        attention = torch.softmax(score, dim=3)\n",
    "        \n",
    "        # [B, h, T, T] * [B, h, T, C/h] -> [B, h, T, C/h]\n",
    "        # [B, h, T, C/h] -> [B, T, h, C/h]\n",
    "        out = torch.matmul(attention, values_t).transpose(1,2).reshape(B, value_len, self.heads * self.head_dim)\n",
    "        # [B, T, C]\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "# 单个decoder层\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        attn_out = self.attention(x, x, x, src_mask)\n",
    "        x = self.dropout(self.norm1(attn_out + x))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "# 整个decoder\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, vocab_size, num_layers, max_len):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_encoding = PositionalEncoding(embed_size, max_len)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerDecoderLayer(embed_size, heads, forward_expansion, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:40:33.875403Z",
     "start_time": "2024-07-25T15:40:33.854936Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.chars = sorted(list(set(data)))\n",
    "        self.char_to_index = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.index_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "        self.data = data\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.data[index:index+self.sequence_length]\n",
    "        targets = self.data[index+1:index+self.sequence_length+1]\n",
    "        return torch.tensor([self.char_to_index[ch] for ch in inputs], dtype=torch.long), \\\n",
    "               torch.tensor([self.char_to_index[ch] for ch in targets], dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:40:34.111128Z",
     "start_time": "2024-07-25T15:40:34.103028Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型架构设置\n",
    "\n",
    "- seq_len: 训练时上下文长度，T\n",
    "- embed_size：隐含状态维度：C\n",
    "- head：注意力头数：h\n",
    "- forward_expansion：FFN层膨胀系数，h -> nh -> h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "embed_size = 256\n",
    "heads = 4\n",
    "forward_expansion = 1\n",
    "decoder_layers = 2\n",
    "max_position_embeddings = 4096"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:40:34.583366Z",
     "start_time": "2024-07-25T15:40:34.579868Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练超参数设置\n",
    "\n",
    "- dropout：在训练的时候我们随即将一些参数置为0，推理的时候启动全部参数然后乘以一个归一化系数 1/(1-dropout)\n",
    "- learning_rate: 每一步更新的大小\n",
    "- EPOCH：所有数据看一遍叫做一个epoch，在大模型场景下我们一般只看一遍\n",
    "- BATCH_SIZE：训练批次大小，一次性喂入GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DROPOUT = 0.1\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:47:03.866562Z",
     "start_time": "2024-07-25T15:47:03.861908Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 初始化\n",
    "\n",
    "- dataset & dataloader：PyTorch提供，shuffle，batch，str2idx\n",
    "- model：传入模型\n",
    "- device：CPU or GPU\n",
    "- criterion：分类问题，使用交叉熵损失函数\n",
    "- optimizer：使用Adam，比朴素SGD更好，恒定lr应该不是最好的策略 -_-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 3951\n",
      "embedding lookup table: {'\\n': 0, ' ': 1, '*': 2, '?': 3, '[': 4, ']': 5, '—': 6, '‘': 7, '’': 8, '“': 9, '”': 10, '…': 11, '□': 12, '\\u3000': 13, '、': 14, '。': 15, '《': 16, '》': 17, '【': 18, '】': 19, '一': 20, '丁': 21, '七': 22, '万': 23, '丈': 24, '三': 25, '上': 26, '下': 27, '不': 28, '与': 29, '丐': 30, '丑': 31, '专': 32, '且': 33, '丕': 34, '世': 35, '丘': 36, '丙': 37, '业': 38, '丛': 39, '东': 40, '丝': 41, '丞': 42, '丢': 43, '两': 44, '严': 45, '丧': 46, '个': 47, '中': 48, '丰': 49, '临': 50, '丸': 51, '丹': 52, '为': 53, '主': 54, '丽': 55, '举': 56, '乂': 57, '乃': 58, '久': 59, '么': 60, '义': 61, '之': 62, '乌': 63, '乎': 64, '乏': 65, '乐': 66, '乔': 67, '乖': 68, '乘': 69, '乙': 70, '九': 71, '乞': 72, '也': 73, '习': 74, '乡': 75, '书': 76, '买': 77, '乱': 78, '乳': 79, '乾': 80, '了': 81, '予': 82, '争': 83, '事': 84, '二': 85, '于': 86, '亏': 87, '云': 88, '互': 89, '五': 90, '井': 91, '亘': 92, '亚': 93, '些': 94, '亟': 95, '亡': 96, '亢': 97, '交': 98, '亥': 99, '亦': 100, '产': 101, '亨': 102, '亩': 103, '享': 104, '京': 105, '亭': 106, '亮': 107, '亲': 108, '亵': 109, '亹': 110, '人': 111, '什': 112, '仁': 113, '仅': 114, '仆': 115, '仇': 116, '今': 117, '介': 118, '仍': 119, '从': 120, '仓': 121, '仔': 122, '仕': 123, '他': 124, '仗': 125, '付': 126, '仙': 127, '仞': 128, '代': 129, '令': 130, '以': 131, '仪': 132, '们': 133, '仰': 134, '仲': 135, '件': 136, '价': 137, '任': 138, '仿': 139, '伉': 140, '伊': 141, '伍': 142, '伎': 143, '伏': 144, '伐': 145, '休': 146, '众': 147, '优': 148, '伙': 149, '会': 150, '伞': 151, '伟': 152, '传': 153, '伤': 154, '伦': 155, '伪': 156, '伯': 157, '伴': 158, '伷': 159, '伸': 160, '伺': 161, '似': 162, '但': 163, '位': 164, '低': 165, '住': 166, '佐': 167, '佑': 168, '体': 169, '何': 170, '佗': 171, '余': 172, '佛': 173, '作': 174, '佞': 175, '你': 176, '佣': 177, '佥': 178, '佩': 179, '佯': 180, '佳': 181, '佻': 182, '使': 183, '侄': 184, '侈': 185, '例': 186, '侍': 187, '供': 188, '依': 189, '侠': 190, '侥': 191, '侧': 192, '侪': 193, '侮': 194, '侯': 195, '侵': 196, '便': 197, '促': 198, '俄': 199, '俊': 200, '俎': 201, '俗': 202, '俘': 203, '保': 204, '俞': 205, '俟': 206, '信': 207, '俦': 208, '俨': 209, '俭': 210, '修': 211, '俯': 212, '俱': 213, '俸': 214, '俺': 215, '俾': 216, '倅': 217, '倍': 218, '倏': 219, '倒': 220, '倘': 221, '候': 222, '倚': 223, '借': 224, '倡': 225, '倥': 226, '倦': 227, '值': 228, '倾': 229, '偃': 230, '假': 231, '偎': 232, '偏': 233, '偕': 234, '做': 235, '停': 236, '健': 237, '偬': 238, '偶': 239, '偷': 240, '偿': 241, '傅': 242, '傍': 243, '傕': 244, '储': 245, '催': 246, '傲': 247, '像': 248, '僚': 249, '僧': 250, '僭': 251, '僮': 252, '僵': 253, '僻': 254, '儁': 255, '儒': 256, '儿': 257, '兀': 258, '允': 259, '元': 260, '兄': 261, '充': 262, '兆': 263, '先': 264, '光': 265, '克': 266, '免': 267, '兔': 268, '兖': 269, '党': 270, '兜': 271, '兢': 272, '入': 273, '全': 274, '八': 275, '公': 276, '六': 277, '兮': 278, '兰': 279, '共': 280, '关': 281, '兴': 282, '兵': 283, '其': 284, '具': 285, '典': 286, '兹': 287, '养': 288, '兼': 289, '兽': 290, '冀': 291, '内': 292, '冈': 293, '册': 294, '再': 295, '冒': 296, '冓': 297, '冕': 298, '冗': 299, '写': 300, '军': 301, '农': 302, '冠': 303, '冢': 304, '冤': 305, '冥': 306, '冬': 307, '冯': 308, '冰': 309, '冲': 310, '决': 311, '况': 312, '冶': 313, '冷': 314, '冻': 315, '净': 316, '凄': 317, '准': 318, '凉': 319, '凋': 320, '凌': 321, '减': 322, '凑': 323, '凛': 324, '凝': 325, '几': 326, '凡': 327, '凤': 328, '凭': 329, '凯': 330, '凰': 331, '凳': 332, '凶': 333, '凹': 334, '出': 335, '击': 336, '函': 337, '凿': 338, '刀': 339, '刁': 340, '刃': 341, '分': 342, '切': 343, '刈': 344, '刎': 345, '刑': 346, '划': 347, '刖': 348, '列': 349, '刘': 350, '则': 351, '刚': 352, '创': 353, '初': 354, '判': 355, '利': 356, '别': 357, '刮': 358, '到': 359, '制': 360, '刺': 361, '刻': 362, '刽': 363, '剁': 364, '剂': 365, '削': 366, '前': 367, '剐': 368, '剑': 369, '剔': 370, '剖': 371, '剜': 372, '剥': 373, '剧': 374, '剩': 375, '剪': 376, '副': 377, '割': 378, '剽': 379, '剿': 380, '劈': 381, '力': 382, '劝': 383, '办': 384, '功': 385, '加': 386, '务': 387, '劣': 388, '动': 389, '助': 390, '努': 391, '劫': 392, '劬': 393, '劭': 394, '励': 395, '劲': 396, '劳': 397, '劾': 398, '势': 399, '勃': 400, '勇': 401, '勉': 402, '勋': 403, '勑': 404, '勒': 405, '勖': 406, '勘': 407, '募': 408, '勤': 409, '勺': 410, '勾': 411, '勿': 412, '匄': 413, '包': 414, '匆': 415, '匍': 416, '匐': 417, '化': 418, '北': 419, '匙': 420, '匝': 421, '匠': 422, '匡': 423, '匣': 424, '匪': 425, '匮': 426, '匹': 427, '区': 428, '医': 429, '匿': 430, '十': 431, '千': 432, '升': 433, '午': 434, '半': 435, '华': 436, '协': 437, '卑': 438, '卒': 439, '卓': 440, '单': 441, '卖': 442, '南': 443, '博': 444, '卜': 445, '卞': 446, '占': 447, '卢': 448, '卣': 449, '卤': 450, '卦': 451, '卧': 452, '卫': 453, '卯': 454, '印': 455, '危': 456, '即': 457, '却': 458, '卵': 459, '卷': 460, '卸': 461, '卿': 462, '厄': 463, '厅': 464, '历': 465, '厉': 466, '压': 467, '厌': 468, '厔': 469, '厕': 470, '厘': 471, '厚': 472, '原': 473, '厢': 474, '厥': 475, '厦': 476, '厨': 477, '厮': 478, '去': 479, '县': 480, '参': 481, '又': 482, '叉': 483, '及': 484, '友': 485, '双': 486, '反': 487, '发': 488, '叔': 489, '取': 490, '受': 491, '变': 492, '叙': 493, '叛': 494, '叟': 495, '叠': 496, '口': 497, '古': 498, '句': 499, '另': 500, '叨': 501, '叩': 502, '只': 503, '叫': 504, '召': 505, '叮': 506, '可': 507, '台': 508, '叱': 509, '史': 510, '右': 511, '叵': 512, '叶': 513, '号': 514, '司': 515, '叹': 516, '吁': 517, '吃': 518, '各': 519, '合': 520, '吉': 521, '吊': 522, '同': 523, '名': 524, '后': 525, '吏': 526, '吐': 527, '向': 528, '吓': 529, '吕': 530, '君': 531, '吝': 532, '吞': 533, '吟': 534, '吠': 535, '否': 536, '含': 537, '听': 538, '启': 539, '吴': 540, '吸': 541, '吹': 542, '吻': 543, '吼': 544, '吾': 545, '呀': 546, '呆': 547, '呈': 548, '告': 549, '呐': 550, '呕': 551, '员': 552, '呜': 553, '呦': 554, '周': 555, '味': 556, '呵': 557, '呻': 558, '呼': 559, '命': 560, '咆': 561, '和': 562, '咎': 563, '咏': 564, '咐': 565, '咒': 566, '咛': 567, '咥': 568, '咨': 569, '咫': 570, '咬': 571, '咸': 572, '咽': 573, '哀': 574, '品': 575, '哂': 576, '哄': 577, '哉': 578, '响': 579, '哑': 580, '哙': 581, '哥': 582, '哨': 583, '哩': 584, '哭': 585, '哮': 586, '哲': 587, '哺': 588, '哽': 589, '唆': 590, '唇': 591, '唐': 592, '唤': 593, '唬': 594, '唯': 595, '唱': 596, '唾': 597, '唿': 598, '商': 599, '啕': 600, '啖': 601, '啜': 602, '啸': 603, '啼': 604, '喂': 605, '喃': 606, '善': 607, '喈': 608, '喉': 609, '喊': 610, '喏': 611, '喘': 612, '喜': 613, '喝': 614, '喟': 615, '喧': 616, '喨': 617, '喷': 618, '喻': 619, '嗓': 620, '嗔': 621, '嗜': 622, '嗟': 623, '嗣': 624, '嗤': 625, '嘉': 626, '嘏': 627, '嘤': 628, '嘱': 629, '嘴': 630, '嘶': 631, '嘹': 632, '噀': 633, '噎': 634, '噤': 635, '器': 636, '噪': 637, '噫': 638, '噬': 639, '嚎': 640, '嚷': 641, '嚼': 642, '囊': 643, '囚': 644, '四': 645, '回': 646, '因': 647, '团': 648, '囧': 649, '园': 650, '困': 651, '围': 652, '囷': 653, '固': 654, '国': 655, '图': 656, '圃': 657, '圆': 658, '圈': 659, '土': 660, '圣': 661, '在': 662, '圭': 663, '地': 664, '场': 665, '坂': 666, '均': 667, '坊': 668, '坌': 669, '坎': 670, '坏': 671, '坐': 672, '坑': 673, '块': 674, '坚': 675, '坛': 676, '坞': 677, '坟': 678, '坠': 679, '坡': 680, '坤': 681, '坦': 682, '垂': 683, '垒': 684, '垓': 685, '垕': 686, '垛': 687, '垠': 688, '垢': 689, '垣': 690, '垦': 691, '垫': 692, '埃': 693, '埋': 694, '城': 695, '域': 696, '基': 697, '堂': 698, '堆': 699, '堑': 700, '堕': 701, '堤': 702, '堪': 703, '堰': 704, '堵': 705, '塌': 706, '塑': 707, '塔': 708, '塘': 709, '塞': 710, '填': 711, '墀': 712, '境': 713, '墉': 714, '墓': 715, '墙': 716, '增': 717, '墟': 718, '墨': 719, '墩': 720, '墵': 721, '壁': 722, '壎': 723, '壑': 724, '壕': 725, '壤': 726, '士': 727, '壬': 728, '壮': 729, '声': 730, '壳': 731, '壶': 732, '处': 733, '备': 734, '复': 735, '夏': 736, '夔': 737, '夕': 738, '外': 739, '夙': 740, '多': 741, '夜': 742, '够': 743, '夤': 744, '夥': 745, '大': 746, '天': 747, '太': 748, '夫': 749, '夭': 750, '央': 751, '失': 752, '头': 753, '夷': 754, '夸': 755, '夹': 756, '夺': 757, '奁': 758, '奂': 759, '奄': 760, '奇': 761, '奈': 762, '奉': 763, '奋': 764, '奎': 765, '奏': 766, '契': 767, '奔': 768, '奕': 769, '奖': 770, '套': 771, '奚': 772, '奠': 773, '奢': 774, '奥': 775, '女': 776, '奴': 777, '奸': 778, '好': 779, '如': 780, '妃': 781, '妄': 782, '妆': 783, '妇': 784, '妒': 785, '妓': 786, '妖': 787, '妙': 788, '妥': 789, '妨': 790, '妫': 791, '妹': 792, '妻': 793, '妾': 794, '姊': 795, '始': 796, '姐': 797, '姑': 798, '姓': 799, '委': 800, '姚': 801, '姜': 802, '姬': 803, '姻': 804, '姿': 805, '威': 806, '娄': 807, '娇': 808, '娘': 809, '娥': 810, '娩': 811, '娱': 812, '娴': 813, '娶': 814, '娼': 815, '婆': 816, '婉': 817, '婚': 818, '婢': 819, '婴': 820, '婿': 821, '媒': 822, '媚': 823, '嫁': 824, '嫂': 825, '嫉': 826, '嫌': 827, '嫔': 828, '嫡': 829, '嫩': 830, '嬉': 831, '嬖': 832, '嬴': 833, '子': 834, '孑': 835, '孔': 836, '孕': 837, '字': 838, '存': 839, '孙': 840, '孚': 841, '孝': 842, '孟': 843, '季': 844, '孤': 845, '孥': 846, '学': 847, '孩': 848, '孰': 849, '孱': 850, '孺': 851, '孽': 852, '宁': 853, '宄': 854, '宅': 855, '宇': 856, '守': 857, '安': 858, '宋': 859, '完': 860, '宏': 861, '宓': 862, '宕': 863, '宗': 864, '官': 865, '宙': 866, '定': 867, '宛': 868, '宜': 869, '宝': 870, '实': 871, '宠': 872, '审': 873, '客': 874, '宣': 875, '室': 876, '宥': 877, '宦': 878, '宪': 879, '宫': 880, '宰': 881, '害': 882, '宴': 883, '宵': 884, '家': 885, '容': 886, '宽': 887, '宾': 888, '宿': 889, '寂': 890, '寄': 891, '寅': 892, '密': 893, '寇': 894, '富': 895, '寐': 896, '寒': 897, '寓': 898, '寔': 899, '寝': 900, '寞': 901, '察': 902, '寡': 903, '寤': 904, '寨': 905, '寮': 906, '寰': 907, '寸': 908, '对': 909, '寺': 910, '寻': 911, '导': 912, '寿': 913, '封': 914, '射': 915, '将': 916, '尉': 917, '尊': 918, '小': 919, '少': 920, '尔': 921, '尖': 922, '尘': 923, '尚': 924, '尝': 925, '尤': 926, '尧': 927, '尪': 928, '就': 929, '尸': 930, '尹': 931, '尺': 932, '尼': 933, '尽': 934, '尾': 935, '局': 936, '层': 937, '居': 938, '屈': 939, '屋': 940, '屏': 941, '屑': 942, '展': 943, '属': 944, '屠': 945, '屡': 946, '履': 947, '屦': 948, '屯': 949, '山': 950, '岁': 951, '岂': 952, '岌': 953, '岐': 954, '岑': 955, '岖': 956, '岗': 957, '岘': 958, '岛': 959, '岩': 960, '岭': 961, '岱': 962, '岳': 963, '岷': 964, '岸': 965, '峙': 966, '峡': 967, '峨': 968, '峪': 969, '峭': 970, '峰': 971, '峻': 972, '崇': 973, '崎': 974, '崔': 975, '崖': 976, '崤': 977, '崦': 978, '崩': 979, '嵋': 980, '嵌': 981, '嵩': 982, '嵯': 983, '嶲': 984, '嶷': 985, '巅': 986, '巍': 987, '川': 988, '州': 989, '巡': 990, '巢': 991, '工': 992, '左': 993, '巧': 994, '巨': 995, '巩': 996, '巫': 997, '差': 998, '己': 999, '已': 1000, '巳': 1001, '巴': 1002, '巷': 1003, '巽': 1004, '巾': 1005, '币': 1006, '市': 1007, '布': 1008, '帅': 1009, '帆': 1010, '师': 1011, '希': 1012, '帏': 1013, '帐': 1014, '帕': 1015, '帖': 1016, '帘': 1017, '帙': 1018, '帚': 1019, '帛': 1020, '帜': 1021, '帝': 1022, '带': 1023, '席': 1024, '帮': 1025, '帷': 1026, '常': 1027, '帻': 1028, '帼': 1029, '帽': 1030, '幄': 1031, '幅': 1032, '幔': 1033, '幕': 1034, '幡': 1035, '幢': 1036, '干': 1037, '平': 1038, '年': 1039, '并': 1040, '幸': 1041, '幻': 1042, '幼': 1043, '幽': 1044, '广': 1045, '庄': 1046, '庆': 1047, '庇': 1048, '床': 1049, '序': 1050, '庐': 1051, '庑': 1052, '库': 1053, '应': 1054, '底': 1055, '庖': 1056, '店': 1057, '庙': 1058, '庚': 1059, '府': 1060, '庞': 1061, '废': 1062, '度': 1063, '座': 1064, '庭': 1065, '庵': 1066, '庶': 1067, '康': 1068, '庸': 1069, '庾': 1070, '廉': 1071, '廊': 1072, '廒': 1073, '廖': 1074, '廙': 1075, '廛': 1076, '廨': 1077, '廪': 1078, '延': 1079, '廷': 1080, '建': 1081, '开': 1082, '异': 1083, '弃': 1084, '弄': 1085, '弇': 1086, '弈': 1087, '弊': 1088, '式': 1089, '弑': 1090, '弓': 1091, '引': 1092, '弗': 1093, '弘': 1094, '弛': 1095, '弟': 1096, '张': 1097, '弥': 1098, '弦': 1099, '弩': 1100, '弯': 1101, '弱': 1102, '弹': 1103, '强': 1104, '弼': 1105, '归': 1106, '当': 1107, '录': 1108, '彘': 1109, '彝': 1110, '形': 1111, '彤': 1112, '彦': 1113, '彧': 1114, '彩': 1115, '彪': 1116, '彬': 1117, '彭': 1118, '彰': 1119, '影': 1120, '彷': 1121, '役': 1122, '彻': 1123, '彼': 1124, '往': 1125, '征': 1126, '徂': 1127, '径': 1128, '待': 1129, '徇': 1130, '徊': 1131, '律': 1132, '徐': 1133, '徒': 1134, '得': 1135, '徘': 1136, '徙': 1137, '徜': 1138, '御': 1139, '徨': 1140, '循': 1141, '徭': 1142, '微': 1143, '徵': 1144, '德': 1145, '徼': 1146, '徽': 1147, '心': 1148, '忄': 1149, '必': 1150, '忆': 1151, '忌': 1152, '忍': 1153, '忒': 1154, '忖': 1155, '志': 1156, '忘': 1157, '忙': 1158, '忝': 1159, '忠': 1160, '忤': 1161, '忧': 1162, '快': 1163, '念': 1164, '忻': 1165, '忽': 1166, '忿': 1167, '怀': 1168, '态': 1169, '怅': 1170, '怆': 1171, '怎': 1172, '怏': 1173, '怒': 1174, '怕': 1175, '怖': 1176, '怜': 1177, '思': 1178, '怠': 1179, '急': 1180, '性': 1181, '怨': 1182, '怪': 1183, '怬': 1184, '怯': 1185, '总': 1186, '怿': 1187, '恁': 1188, '恂': 1189, '恃': 1190, '恋': 1191, '恍': 1192, '恐': 1193, '恒': 1194, '恕': 1195, '恙': 1196, '恢': 1197, '恣': 1198, '恤': 1199, '恨': 1200, '恩': 1201, '恪': 1202, '恬': 1203, '恭': 1204, '息': 1205, '恰': 1206, '恳': 1207, '恶': 1208, '恸': 1209, '恺': 1210, '恼': 1211, '恽': 1212, '悃': 1213, '悄': 1214, '悉': 1215, '悌': 1216, '悍': 1217, '悒': 1218, '悔': 1219, '悖': 1220, '悚': 1221, '悟': 1222, '悠': 1223, '患': 1224, '悦': 1225, '悬': 1226, '悯': 1227, '悲': 1228, '悴': 1229, '悼': 1230, '情': 1231, '惆': 1232, '惇': 1233, '惊': 1234, '惑': 1235, '惕': 1236, '惚': 1237, '惜': 1238, '惟': 1239, '惠': 1240, '惧': 1241, '惨': 1242, '惫': 1243, '惭': 1244, '惮': 1245, '惯': 1246, '惰': 1247, '想': 1248, '惶': 1249, '惹': 1250, '愀': 1251, '愁': 1252, '愆': 1253, '愈': 1254, '愉': 1255, '愍': 1256, '意': 1257, '愕': 1258, '愚': 1259, '感': 1260, '愠': 1261, '愤': 1262, '愧': 1263, '愬': 1264, '愿': 1265, '慄': 1266, '慈': 1267, '慌': 1268, '慎': 1269, '慑': 1270, '慓': 1271, '慕': 1272, '慢': 1273, '慧': 1274, '慨': 1275, '慰': 1276, '慵': 1277, '慷': 1278, '憎': 1279, '憔': 1280, '憩': 1281, '憾': 1282, '懈': 1283, '懊': 1284, '懋': 1285, '懑': 1286, '懒': 1287, '懔': 1288, '懦': 1289, '懿': 1290, '戆': 1291, '戈': 1292, '戊': 1293, '戌': 1294, '戍': 1295, '戎': 1296, '戏': 1297, '成': 1298, '我': 1299, '戒': 1300, '戕': 1301, '或': 1302, '战': 1303, '戚': 1304, '戟': 1305, '戢': 1306, '截': 1307, '戮': 1308, '戳': 1309, '戴': 1310, '户': 1311, '戾': 1312, '房': 1313, '所': 1314, '扁': 1315, '扇': 1316, '扈': 1317, '扉': 1318, '手': 1319, '才': 1320, '扎': 1321, '扑': 1322, '扒': 1323, '打': 1324, '托': 1325, '扛': 1326, '扣': 1327, '执': 1328, '扫': 1329, '扬': 1330, '扭': 1331, '扮': 1332, '扯': 1333, '扰': 1334, '扳': 1335, '扶': 1336, '批': 1337, '扼': 1338, '承': 1339, '抄': 1340, '把': 1341, '抑': 1342, '抒': 1343, '抓': 1344, '投': 1345, '抖': 1346, '抗': 1347, '折': 1348, '抚': 1349, '抛': 1350, '抟': 1351, '抠': 1352, '抡': 1353, '抢': 1354, '护': 1355, '报': 1356, '披': 1357, '抬': 1358, '抱': 1359, '抵': 1360, '抹': 1361, '押': 1362, '抽': 1363, '拂': 1364, '担': 1365, '拆': 1366, '拈': 1367, '拉': 1368, '拊': 1369, '拍': 1370, '拒': 1371, '拓': 1372, '拔': 1373, '拖': 1374, '拗': 1375, '拘': 1376, '拙': 1377, '拚': 1378, '招': 1379, '拜': 1380, '拟': 1381, '拣': 1382, '拥': 1383, '拦': 1384, '拨': 1385, '择': 1386, '括': 1387, '拭': 1388, '拯': 1389, '拱': 1390, '拳': 1391, '拴': 1392, '拷': 1393, '拼': 1394, '拽': 1395, '拾': 1396, '拿': 1397, '持': 1398, '挂': 1399, '指': 1400, '按': 1401, '挑': 1402, '挖': 1403, '挝': 1404, '挞': 1405, '挟': 1406, '挠': 1407, '挡': 1408, '挣': 1409, '挤': 1410, '挥': 1411, '挨': 1412, '挫': 1413, '振': 1414, '挺': 1415, '挽': 1416, '捆': 1417, '捉': 1418, '捍': 1419, '捎': 1420, '捏': 1421, '捐': 1422, '捕': 1423, '捞': 1424, '损': 1425, '换': 1426, '捧': 1427, '据': 1428, '捱': 1429, '捶': 1430, '捷': 1431, '捻': 1432, '捽': 1433, '掀': 1434, '授': 1435, '掉': 1436, '掌': 1437, '掎': 1438, '排': 1439, '掖': 1440, '掘': 1441, '掠': 1442, '探': 1443, '掣': 1444, '接': 1445, '控': 1446, '推': 1447, '掩': 1448, '措': 1449, '掬': 1450, '掳': 1451, '掷': 1452, '掾': 1453, '揎': 1454, '描': 1455, '提': 1456, '插': 1457, '揖': 1458, '握': 1459, '揣': 1460, '揪': 1461, '揭': 1462, '揲': 1463, '援': 1464, '揽': 1465, '搀': 1466, '搂': 1467, '搅': 1468, '搏': 1469, '搔': 1470, '搜': 1471, '搠': 1472, '搦': 1473, '搪': 1474, '搬': 1475, '搭': 1476, '搴': 1477, '携': 1478, '摄': 1479, '摆': 1480, '摇': 1481, '摔': 1482, '摘': 1483, '摧': 1484, '摩': 1485, '摸': 1486, '撄': 1487, '撇': 1488, '撑': 1489, '撒': 1490, '撚': 1491, '撞': 1492, '撤': 1493, '撩': 1494, '播': 1495, '撰': 1496, '撺': 1497, '撼': 1498, '擂': 1499, '擅': 1500, '操': 1501, '擎': 1502, '擐': 1503, '擒': 1504, '擞': 1505, '擢': 1506, '擦': 1507, '攀': 1508, '攒': 1509, '攘': 1510, '支': 1511, '收': 1512, '攸': 1513, '改': 1514, '攻': 1515, '放': 1516, '政': 1517, '故': 1518, '效': 1519, '敌': 1520, '敏': 1521, '救': 1522, '敕': 1523, '敖': 1524, '教': 1525, '敛': 1526, '敝': 1527, '敞': 1528, '敢': 1529, '散': 1530, '敦': 1531, '敬': 1532, '数': 1533, '敲': 1534, '整': 1535, '敷': 1536, '文': 1537, '斋': 1538, '斌': 1539, '斐': 1540, '斑': 1541, '斗': 1542, '料': 1543, '斛': 1544, '斜': 1545, '斟': 1546, '斡': 1547, '斤': 1548, '斥': 1549, '斧': 1550, '斩': 1551, '斫': 1552, '断': 1553, '斯': 1554, '新': 1555, '方': 1556, '於': 1557, '施': 1558, '旁': 1559, '旂': 1560, '旄': 1561, '旅': 1562, '旆': 1563, '旋': 1564, '旌': 1565, '族': 1566, '旒': 1567, '旗': 1568, '旙': 1569, '无': 1570, '既': 1571, '日': 1572, '旦': 1573, '旧': 1574, '旨': 1575, '早': 1576, '旬': 1577, '旰': 1578, '旱': 1579, '时': 1580, '旷': 1581, '旺': 1582, '旻': 1583, '昂': 1584, '昃': 1585, '昆': 1586, '昊': 1587, '昌': 1588, '明': 1589, '昏': 1590, '易': 1591, '昔': 1592, '星': 1593, '映': 1594, '春': 1595, '昧': 1596, '昨': 1597, '昭': 1598, '是': 1599, '昱': 1600, '昴': 1601, '昶': 1602, '昼': 1603, '显': 1604, '晃': 1605, '晋': 1606, '晌': 1607, '晏': 1608, '晒': 1609, '晓': 1610, '晔': 1611, '晙': 1612, '晚': 1613, '晤': 1614, '晦': 1615, '晨': 1616, '普': 1617, '景': 1618, '晴': 1619, '智': 1620, '暂': 1621, '暇': 1622, '暑': 1623, '暖': 1624, '暗': 1625, '暨': 1626, '暮': 1627, '暴': 1628, '暹': 1629, '曜': 1630, '曩': 1631, '曰': 1632, '曲': 1633, '更': 1634, '曷': 1635, '曹': 1636, '曼': 1637, '曾': 1638, '替': 1639, '最': 1640, '月': 1641, '有': 1642, '朋': 1643, '服': 1644, '朐': 1645, '朔': 1646, '朕': 1647, '朗': 1648, '望': 1649, '朝': 1650, '期': 1651, '朦': 1652, '木': 1653, '未': 1654, '末': 1655, '本': 1656, '札': 1657, '术': 1658, '朱': 1659, '朴': 1660, '朵': 1661, '机': 1662, '朽': 1663, '杀': 1664, '杂': 1665, '权': 1666, '杆': 1667, '杉': 1668, '李': 1669, '材': 1670, '村': 1671, '杖': 1672, '杜': 1673, '束': 1674, '杠': 1675, '条': 1676, '来': 1677, '杨': 1678, '杭': 1679, '杯': 1680, '杰': 1681, '杳': 1682, '杵': 1683, '松': 1684, '板': 1685, '极': 1686, '构': 1687, '枉': 1688, '析': 1689, '枒': 1690, '枕': 1691, '林': 1692, '枚': 1693, '果': 1694, '枝': 1695, '枢': 1696, '枣': 1697, '枪': 1698, '枫': 1699, '枭': 1700, '枯': 1701, '枰': 1702, '枳': 1703, '架': 1704, '枷': 1705, '枹': 1706, '柄': 1707, '柏': 1708, '某': 1709, '柑': 1710, '染': 1711, '柔': 1712, '柜': 1713, '查': 1714, '柩': 1715, '柯': 1716, '柱': 1717, '柳': 1718, '柴': 1719, '栅': 1720, '标': 1721, '栈': 1722, '栉': 1723, '栊': 1724, '栋': 1725, '栎': 1726, '栏': 1727, '树': 1728, '栖': 1729, '栗': 1730, '校': 1731, '株': 1732, '样': 1733, '核': 1734, '根': 1735, '格': 1736, '栽': 1737, '桀': 1738, '桂': 1739, '桃': 1740, '案': 1741, '桌': 1742, '桐': 1743, '桑': 1744, '桓': 1745, '桔': 1746, '桥': 1747, '桧': 1748, '桨': 1749, '桩': 1750, '桶': 1751, '梁': 1752, '梅': 1753, '梆': 1754, '梓': 1755, '梢': 1756, '梦': 1757, '梧': 1758, '梨': 1759, '梯': 1760, '械': 1761, '梳': 1762, '检': 1763, '棉': 1764, '棋': 1765, '棍': 1766, '棒': 1767, '棘': 1768, '棚': 1769, '森': 1770, '棹': 1771, '棺': 1772, '椁': 1773, '椅': 1774, '植': 1775, '椒': 1776, '椽': 1777, '楙': 1778, '楚': 1779, '楞': 1780, '楫': 1781, '楮': 1782, '楯': 1783, '楷': 1784, '楼': 1785, '概': 1786, '榆': 1787, '榇': 1788, '榛': 1789, '榜': 1790, '榻': 1791, '槁': 1792, '槊': 1793, '槎': 1794, '槛': 1795, '槽': 1796, '樊': 1797, '樗': 1798, '模': 1799, '横': 1800, '樯': 1801, '樱': 1802, '樵': 1803, '樽': 1804, '橹': 1805, '檀': 1806, '檄': 1807, '欠': 1808, '次': 1809, '欢': 1810, '欣': 1811, '欤': 1812, '欲': 1813, '欷': 1814, '欺': 1815, '款': 1816, '歃': 1817, '歆': 1818, '歇': 1819, '歉': 1820, '歌': 1821, '歔': 1822, '止': 1823, '正': 1824, '此': 1825, '步': 1826, '武': 1827, '歹': 1828, '死': 1829, '歼': 1830, '殁': 1831, '殂': 1832, '殃': 1833, '殄': 1834, '殆': 1835, '殉': 1836, '殊': 1837, '残': 1838, '殒': 1839, '殓': 1840, '殖': 1841, '殚': 1842, '殛': 1843, '殡': 1844, '殪': 1845, '殴': 1846, '段': 1847, '殷': 1848, '殿': 1849, '毁': 1850, '毅': 1851, '毋': 1852, '母': 1853, '每': 1854, '毒': 1855, '毓': 1856, '比': 1857, '毕': 1858, '毖': 1859, '毗': 1860, '毙': 1861, '毛': 1862, '毡': 1863, '毫': 1864, '氅': 1865, '氏': 1866, '民': 1867, '气': 1868, '氛': 1869, '水': 1870, '永': 1871, '汁': 1872, '求': 1873, '汇': 1874, '汉': 1875, '汗': 1876, '汙': 1877, '汜': 1878, '汝': 1879, '江': 1880, '池': 1881, '污': 1882, '汤': 1883, '汪': 1884, '汰': 1885, '汲': 1886, '汶': 1887, '汹': 1888, '沂': 1889, '沃': 1890, '沅': 1891, '沆': 1892, '沈': 1893, '沉': 1894, '沌': 1895, '沐': 1896, '沓': 1897, '沔': 1898, '沙': 1899, '沛': 1900, '沟': 1901, '没': 1902, '沥': 1903, '沦': 1904, '沧': 1905, '沪': 1906, '沮': 1907, '沱': 1908, '河': 1909, '沸': 1910, '油': 1911, '治': 1912, '沽': 1913, '沾': 1914, '沿': 1915, '泄': 1916, '泉': 1917, '泊': 1918, '泌': 1919, '法': 1920, '泗': 1921, '泛': 1922, '泞': 1923, '泠': 1924, '波': 1925, '泣': 1926, '泥': 1927, '注': 1928, '泪': 1929, '泯': 1930, '泰': 1931, '泸': 1932, '泼': 1933, '泽': 1934, '泾': 1935, '洁': 1936, '洋': 1937, '洒': 1938, '洗': 1939, '洛': 1940, '洞': 1941, '津': 1942, '洪': 1943, '洮': 1944, '洱': 1945, '洲': 1946, '洹': 1947, '活': 1948, '洽': 1949, '派': 1950, '流': 1951, '浅': 1952, '浆': 1953, '浇': 1954, '浊': 1955, '测': 1956, '济': 1957, '浑': 1958, '浓': 1959, '浔': 1960, '浙': 1961, '浚': 1962, '浦': 1963, '浩': 1964, '浪': 1965, '浮': 1966, '浴': 1967, '海': 1968, '浸': 1969, '浼': 1970, '涂': 1971, '消': 1972, '涉': 1973, '涌': 1974, '涎': 1975, '涓': 1976, '涕': 1977, '涛': 1978, '涝': 1979, '涟': 1980, '涣': 1981, '润': 1982, '涧': 1983, '涨': 1984, '涪': 1985, '液': 1986, '涿': 1987, '淄': 1988, '淆': 1989, '淇': 1990, '淋': 1991, '淑': 1992, '淘': 1993, '淝': 1994, '淡': 1995, '淫': 1996, '淮': 1997, '淯': 1998, '深': 1999, '淳': 2000, '混': 2001, '淹': 2002, '添': 2003, '清': 2004, '渊': 2005, '渎': 2006, '渐': 2007, '渑': 2008, '渔': 2009, '渗': 2010, '渚': 2011, '渝': 2012, '渠': 2013, '渡': 2014, '渤': 2015, '温': 2016, '渭': 2017, '港': 2018, '渴': 2019, '游': 2020, '渺': 2021, '湄': 2022, '湖': 2023, '湘': 2024, '湫': 2025, '湿': 2026, '溃': 2027, '溅': 2028, '源': 2029, '溜': 2030, '溟': 2031, '溢': 2032, '溪': 2033, '溯': 2034, '溺': 2035, '溽': 2036, '滂': 2037, '滋': 2038, '滏': 2039, '滑': 2040, '滔': 2041, '滕': 2042, '滚': 2043, '滞': 2044, '满': 2045, '滥': 2046, '滨': 2047, '滩': 2048, '滴': 2049, '漆': 2050, '漏': 2051, '漓': 2052, '演': 2053, '漠': 2054, '漫': 2055, '漯': 2056, '漳': 2057, '潘': 2058, '潜': 2059, '潢': 2060, '潭': 2061, '潮': 2062, '潸': 2063, '潺': 2064, '潼': 2065, '澄': 2066, '澜': 2067, '激': 2068, '濛': 2069, '濡': 2070, '濦': 2071, '濬': 2072, '濮': 2073, '濯': 2074, '瀣': 2075, '灌': 2076, '火': 2077, '灭': 2078, '灯': 2079, '灰': 2080, '灵': 2081, '灶': 2082, '灸': 2083, '灼': 2084, '灾': 2085, '灿': 2086, '炉': 2087, '炎': 2088, '炜': 2089, '炫': 2090, '炬': 2091, '炭': 2092, '炮': 2093, '炳': 2094, '点': 2095, '烂': 2096, '烈': 2097, '烘': 2098, '烛': 2099, '烝': 2100, '烟': 2101, '烦': 2102, '烧': 2103, '热': 2104, '烹': 2105, '烽': 2106, '焉': 2107, '焕': 2108, '焙': 2109, '焚': 2110, '焦': 2111, '焫': 2112, '焰': 2113, '然': 2114, '煌': 2115, '煎': 2116, '照': 2117, '煨': 2118, '煮': 2119, '煽': 2120, '熊': 2121, '熙': 2122, '熟': 2123, '熬': 2124, '燃': 2125, '燎': 2126, '燕': 2127, '燥': 2128, '爨': 2129, '爪': 2130, '爬': 2131, '爰': 2132, '爱': 2133, '爵': 2134, '父': 2135, '爷': 2136, '爻': 2137, '爽': 2138, '牁': 2139, '牂': 2140, '片': 2141, '版': 2142, '牌': 2143, '牒': 2144, '牙': 2145, '牛': 2146, '牝': 2147, '牟': 2148, '牡': 2149, '牢': 2150, '牧': 2151, '物': 2152, '牲': 2153, '牵': 2154, '特': 2155, '牺': 2156, '犀': 2157, '犊': 2158, '犍': 2159, '犒': 2160, '犬': 2161, '犭': 2162, '犯': 2163, '状': 2164, '犹': 2165, '狂': 2166, '狄': 2167, '狈': 2168, '狎': 2169, '狐': 2170, '狗': 2171, '狝': 2172, '狠': 2173, '狡': 2174, '狩': 2175, '独': 2176, '狭': 2177, '狮': 2178, '狱': 2179, '狼': 2180, '猇': 2181, '猊': 2182, '猎': 2183, '猖': 2184, '猛': 2185, '猜': 2186, '猝': 2187, '猥': 2188, '猪': 2189, '献': 2190, '猾': 2191, '猿': 2192, '獐': 2193, '獗': 2194, '獠': 2195, '獬': 2196, '獭': 2197, '玄': 2198, '率': 2199, '玉': 2200, '王': 2201, '玠': 2202, '玩': 2203, '环': 2204, '现': 2205, '玲': 2206, '玷': 2207, '玺': 2208, '玻': 2209, '珍': 2210, '珑': 2211, '珝': 2212, '珠': 2213, '珩': 2214, '珪': 2215, '班': 2216, '球': 2217, '琅': 2218, '理': 2219, '琊': 2220, '琐': 2221, '琢': 2222, '琦': 2223, '琪': 2224, '琬': 2225, '琮': 2226, '琰': 2227, '琳': 2228, '琴': 2229, '琼': 2230, '瑁': 2231, '瑕': 2232, '瑚': 2233, '瑛': 2234, '瑜': 2235, '瑞': 2236, '瑟': 2237, '瑯': 2238, '瑶': 2239, '瑾': 2240, '璃': 2241, '璆': 2242, '璇': 2243, '璋': 2244, '璜': 2245, '璝': 2246, '璧': 2247, '璩': 2248, '璿': 2249, '瓒': 2250, '瓘': 2251, '瓜': 2252, '瓦': 2253, '瓮': 2254, '瓯': 2255, '瓶': 2256, '甄': 2257, '甑': 2258, '甘': 2259, '甚': 2260, '甜': 2261, '生': 2262, '甥': 2263, '用': 2264, '甫': 2265, '甬': 2266, '田': 2267, '由': 2268, '甲': 2269, '申': 2270, '电': 2271, '男': 2272, '甸': 2273, '画': 2274, '畅': 2275, '畋': 2276, '界': 2277, '畏': 2278, '畔': 2279, '留': 2280, '畜': 2281, '略': 2282, '番': 2283, '畯': 2284, '畴': 2285, '畿': 2286, '疆': 2287, '疏': 2288, '疑': 2289, '疗': 2290, '疠': 2291, '疢': 2292, '疥': 2293, '疫': 2294, '疮': 2295, '疲': 2296, '疴': 2297, '疼': 2298, '疽': 2299, '疾': 2300, '病': 2301, '症': 2302, '痈': 2303, '痊': 2304, '痒': 2305, '痕': 2306, '痛': 2307, '痢': 2308, '痴': 2309, '瘁': 2310, '瘠': 2311, '瘤': 2312, '瘦': 2313, '瘴': 2314, '癖': 2315, '癞': 2316, '癣': 2317, '癸': 2318, '登': 2319, '白': 2320, '百': 2321, '皂': 2322, '的': 2323, '皆': 2324, '皇': 2325, '皈': 2326, '皋': 2327, '皎': 2328, '皓': 2329, '皖': 2330, '皮': 2331, '皿': 2332, '盂': 2333, '盆': 2334, '盈': 2335, '益': 2336, '盍': 2337, '盏': 2338, '盐': 2339, '监': 2340, '盒': 2341, '盔': 2342, '盖': 2343, '盗': 2344, '盘': 2345, '盛': 2346, '盟': 2347, '盩': 2348, '目': 2349, '盱': 2350, '盲': 2351, '直': 2352, '相': 2353, '盼': 2354, '盾': 2355, '省': 2356, '眇': 2357, '眉': 2358, '看': 2359, '眙': 2360, '真': 2361, '眠': 2362, '眦': 2363, '眩': 2364, '眭': 2365, '眷': 2366, '眸': 2367, '眺': 2368, '眼': 2369, '着': 2370, '睁': 2371, '睚': 2372, '睛': 2373, '睡': 2374, '督': 2375, '睦': 2376, '睨': 2377, '睬': 2378, '睹': 2379, '睿': 2380, '瞋': 2381, '瞑': 2382, '瞒': 2383, '瞪': 2384, '瞰': 2385, '瞳': 2386, '瞻': 2387, '矍': 2388, '矛': 2389, '矜': 2390, '矢': 2391, '矣': 2392, '知': 2393, '矩': 2394, '矫': 2395, '短': 2396, '石': 2397, '矴': 2398, '矿': 2399, '砀': 2400, '砂': 2401, '砌': 2402, '砍': 2403, '砖': 2404, '砚': 2405, '破': 2406, '砾': 2407, '硕': 2408, '硝': 2409, '硫': 2410, '硬': 2411, '确': 2412, '碌': 2413, '碍': 2414, '碎': 2415, '碑': 2416, '碗': 2417, '碣': 2418, '碧': 2419, '碱': 2420, '碾': 2421, '磋': 2422, '磐': 2423, '磨': 2424, '磾': 2425, '示': 2426, '礼': 2427, '社': 2428, '祀': 2429, '祁': 2430, '祈': 2431, '祎': 2432, '祐': 2433, '祖': 2434, '祚': 2435, '祜': 2436, '祝': 2437, '神': 2438, '祠': 2439, '祢': 2440, '祥': 2441, '票': 2442, '祭': 2443, '祯': 2444, '祷': 2445, '祸': 2446, '祺': 2447, '禀': 2448, '禁': 2449, '禄': 2450, '禅': 2451, '福': 2452, '禧': 2453, '禳': 2454, '禹': 2455, '离': 2456, '禽': 2457, '禾': 2458, '秀': 2459, '私': 2460, '秃': 2461, '秉': 2462, '秋': 2463, '种': 2464, '科': 2465, '秘': 2466, '租': 2467, '秣': 2468, '秦': 2469, '秩': 2470, '秬': 2471, '秭': 2472, '积': 2473, '称': 2474, '移': 2475, '秽': 2476, '稀': 2477, '程': 2478, '稍': 2479, '税': 2480, '稔': 2481, '稚': 2482, '稠': 2483, '稳': 2484, '稷': 2485, '稻': 2486, '稼': 2487, '稽': 2488, '稿': 2489, '穆': 2490, '穗': 2491, '穰': 2492, '穴': 2493, '究': 2494, '穷': 2495, '穹': 2496, '空': 2497, '穿': 2498, '突': 2499, '窃': 2500, '窄': 2501, '窍': 2502, '窗': 2503, '窘': 2504, '窜': 2505, '窝': 2506, '窟': 2507, '窠': 2508, '窥': 2509, '窦': 2510, '立': 2511, '竖': 2512, '站': 2513, '竞': 2514, '竟': 2515, '章': 2516, '竣': 2517, '童': 2518, '竭': 2519, '端': 2520, '竹': 2521, '竺': 2522, '竿': 2523, '笃': 2524, '笄': 2525, '笑': 2526, '笔': 2527, '笙': 2528, '笛': 2529, '笠': 2530, '符': 2531, '第': 2532, '笮': 2533, '笳': 2534, '笺': 2535, '笼': 2536, '等': 2537, '筋': 2538, '筏': 2539, '筑': 2540, '答': 2541, '策': 2542, '筛': 2543, '筮': 2544, '筵': 2545, '筹': 2546, '简': 2547, '箕': 2548, '算': 2549, '管': 2550, '箧': 2551, '箪': 2552, '箭': 2553, '箱': 2554, '箸': 2555, '篁': 2556, '篆': 2557, '篇': 2558, '篙': 2559, '篡': 2560, '篱': 2561, '篷': 2562, '簇': 2563, '簏': 2564, '簧': 2565, '簪': 2566, '簿': 2567, '籍': 2568, '米': 2569, '类': 2570, '粉': 2571, '粒': 2572, '粗': 2573, '粝': 2574, '粟': 2575, '粥': 2576, '粪': 2577, '粮': 2578, '粱': 2579, '粲': 2580, '粹': 2581, '精': 2582, '糊': 2583, '糜': 2584, '糟': 2585, '系': 2586, '紞': 2587, '素': 2588, '索': 2589, '紧': 2590, '紫': 2591, '累': 2592, '絏': 2593, '絮': 2594, '綝': 2595, '繁': 2596, '繇': 2597, '纂': 2598, '纛': 2599, '纠': 2600, '纡': 2601, '红': 2602, '纣': 2603, '约': 2604, '级': 2605, '纪': 2606, '纬': 2607, '纭': 2608, '纮': 2609, '纯': 2610, '纱': 2611, '纲': 2612, '纳': 2613, '纵': 2614, '纶': 2615, '纷': 2616, '纸': 2617, '纹': 2618, '纽': 2619, '线': 2620, '绁': 2621, '练': 2622, '绅': 2623, '细': 2624, '织': 2625, '终': 2626, '绊': 2627, '绍': 2628, '绎': 2629, '经': 2630, '绑': 2631, '绒': 2632, '结': 2633, '绕': 2634, '绘': 2635, '给': 2636, '绛': 2637, '络': 2638, '绝': 2639, '绞': 2640, '统': 2641, '绢': 2642, '绣': 2643, '绥': 2644, '绦': 2645, '继': 2646, '绩': 2647, '绪': 2648, '绫': 2649, '续': 2650, '绮': 2651, '绰': 2652, '绲': 2653, '绳': 2654, '维': 2655, '绵': 2656, '绶': 2657, '综': 2658, '绽': 2659, '绿': 2660, '缀': 2661, '缄': 2662, '缆': 2663, '缉': 2664, '缎': 2665, '缓': 2666, '缔': 2667, '缕': 2668, '编': 2669, '缘': 2670, '缙': 2671, '缚': 2672, '缝': 2673, '缟': 2674, '缠': 2675, '缢': 2676, '缣': 2677, '缧': 2678, '缨': 2679, '缩': 2680, '缭': 2681, '缮': 2682, '缰': 2683, '缴': 2684, '缵': 2685, '缺': 2686, '罄': 2687, '罐': 2688, '网': 2689, '罔': 2690, '罕': 2691, '罗': 2692, '罚': 2693, '罡': 2694, '罢': 2695, '罩': 2696, '罪': 2697, '置': 2698, '署': 2699, '罹': 2700, '罾': 2701, '羁': 2702, '羊': 2703, '羌': 2704, '美': 2705, '羕': 2706, '羞': 2707, '羡': 2708, '群': 2709, '羲': 2710, '羸': 2711, '羹': 2712, '羽': 2713, '羿': 2714, '翁': 2715, '翅': 2716, '翊': 2717, '翎': 2718, '翔': 2719, '翘': 2720, '翟': 2721, '翠': 2722, '翩': 2723, '翰': 2724, '翱': 2725, '翳': 2726, '翻': 2727, '翼': 2728, '耀': 2729, '老': 2730, '考': 2731, '者': 2732, '耆': 2733, '而': 2734, '耐': 2735, '耑': 2736, '耒': 2737, '耕': 2738, '耗': 2739, '耳': 2740, '耶': 2741, '耸': 2742, '耻': 2743, '耽': 2744, '耿': 2745, '聊': 2746, '聋': 2747, '职': 2748, '联': 2749, '聘': 2750, '聚': 2751, '聪': 2752, '肃': 2753, '肆': 2754, '肉': 2755, '肋': 2756, '肌': 2757, '肓': 2758, '肖': 2759, '肘': 2760, '肚': 2761, '肝': 2762, '肠': 2763, '股': 2764, '肢': 2765, '肤': 2766, '肥': 2767, '肩': 2768, '肯': 2769, '肱': 2770, '育': 2771, '肴': 2772, '肺': 2773, '肿': 2774, '胀': 2775, '胁': 2776, '胃': 2777, '胄': 2778, '胆': 2779, '背': 2780, '胎': 2781, '胖': 2782, '胜': 2783, '胞': 2784, '胡': 2785, '胤': 2786, '胥': 2787, '胧': 2788, '胪': 2789, '胯': 2790, '胶': 2791, '胸': 2792, '能': 2793, '脂': 2794, '脉': 2795, '脊': 2796, '脍': 2797, '脏': 2798, '脐': 2799, '脑': 2800, '脚': 2801, '脯': 2802, '脱': 2803, '脸': 2804, '腊': 2805, '腐': 2806, '腑': 2807, '腔': 2808, '腕': 2809, '腥': 2810, '腮': 2811, '腰': 2812, '腴': 2813, '腹': 2814, '腾': 2815, '腿': 2816, '膀': 2817, '膂': 2818, '膊': 2819, '膏': 2820, '膑': 2821, '膛': 2822, '膝': 2823, '膳': 2824, '膺': 2825, '臂': 2826, '臣': 2827, '臧': 2828, '自': 2829, '臭': 2830, '至': 2831, '致': 2832, '臻': 2833, '臼': 2834, '臾': 2835, '舄': 2836, '舅': 2837, '舆': 2838, '舌': 2839, '舍': 2840, '舒': 2841, '舜': 2842, '舞': 2843, '舟': 2844, '般': 2845, '舰': 2846, '舱': 2847, '舵': 2848, '舸': 2849, '船': 2850, '艘': 2851, '艟': 2852, '艨': 2853, '良': 2854, '艰': 2855, '色': 2856, '艳': 2857, '艺': 2858, '艾': 2859, '节': 2860, '芒': 2861, '芜': 2862, '芝': 2863, '芟': 2864, '芥': 2865, '芦': 2866, '芬': 2867, '花': 2868, '芳': 2869, '芸': 2870, '芽': 2871, '苇': 2872, '苌': 2873, '苍': 2874, '苏': 2875, '苑': 2876, '苒': 2877, '苗': 2878, '苛': 2879, '苞': 2880, '苟': 2881, '若': 2882, '苦': 2883, '英': 2884, '苴': 2885, '苹': 2886, '茂': 2887, '范': 2888, '茅': 2889, '茔': 2890, '茕': 2891, '茨': 2892, '茫': 2893, '茬': 2894, '茵': 2895, '茶': 2896, '荀': 2897, '荆': 2898, '草': 2899, '荏': 2900, '荐': 2901, '荒': 2902, '荡': 2903, '荣': 2904, '荥': 2905, '荧': 2906, '荩': 2907, '荫': 2908, '药': 2909, '荷': 2910, '荻': 2911, '荼': 2912, '莅': 2913, '莒': 2914, '莘': 2915, '莞': 2916, '莩': 2917, '莫': 2918, '莱': 2919, '莲': 2920, '获': 2921, '莹': 2922, '莽': 2923, '菜': 2924, '菲': 2925, '菽': 2926, '萁': 2927, '萃': 2928, '萌': 2929, '萤': 2930, '营': 2931, '萧': 2932, '落': 2933, '葆': 2934, '著': 2935, '葛': 2936, '董': 2937, '葫': 2938, '葬': 2939, '葭': 2940, '葺': 2941, '蒂': 2942, '蒋': 2943, '蒙': 2944, '蒜': 2945, '蒯': 2946, '蒲': 2947, '蒸': 2948, '蒹': 2949, '蒺': 2950, '蒿': 2951, '蓄': 2952, '蓍': 2953, '蓝': 2954, '蓦': 2955, '蓬': 2956, '蔑': 2957, '蔓': 2958, '蔚': 2959, '蔡': 2960, '蔬': 2961, '蔺': 2962, '蔽': 2963, '蕃': 2964, '蕤': 2965, '蕲': 2966, '蕴': 2967, '薄': 2968, '薛': 2969, '薤': 2970, '薨': 2971, '薪': 2972, '薰': 2973, '藁': 2974, '藉': 2975, '藏': 2976, '藐': 2977, '藜': 2978, '藤': 2979, '藩': 2980, '蘸': 2981, '蘼': 2982, '虎': 2983, '虏': 2984, '虐': 2985, '虑': 2986, '虔': 2987, '虚': 2988, '虞': 2989, '虢': 2990, '虫': 2991, '虬': 2992, '虹': 2993, '虽': 2994, '虾': 2995, '虿': 2996, '蚁': 2997, '蚕': 2998, '蛇': 2999, '蛉': 3000, '蛙': 3001, '蛛': 3002, '蛟': 3003, '蛮': 3004, '蛱': 3005, '蜀': 3006, '蜂': 3007, '蜈': 3008, '蜉': 3009, '蜘': 3010, '蜜': 3011, '蜺': 3012, '蜾': 3013, '蝇': 3014, '蝉': 3015, '蝎': 3016, '蝗': 3017, '蝣': 3018, '蝶': 3019, '蝼': 3020, '螂': 3021, '融': 3022, '螟': 3023, '螳': 3024, '螺': 3025, '蟊': 3026, '蟠': 3027, '蠡': 3028, '蠢': 3029, '蠫': 3030, '蠹': 3031, '血': 3032, '衄': 3033, '衅': 3034, '行': 3035, '衍': 3036, '衔': 3037, '街': 3038, '衙': 3039, '衠': 3040, '衡': 3041, '衢': 3042, '衣': 3043, '补': 3044, '表': 3045, '衫': 3046, '衬': 3047, '衮': 3048, '衰': 3049, '衷': 3050, '衽': 3051, '衿': 3052, '袁': 3053, '袄': 3054, '袅': 3055, '袋': 3056, '袍': 3057, '袒': 3058, '袖': 3059, '袛': 3060, '袤': 3061, '被': 3062, '袭': 3063, '裁': 3064, '裂': 3065, '装': 3066, '裒': 3067, '裔': 3068, '裘': 3069, '裙': 3070, '裤': 3071, '裨': 3072, '裴': 3073, '裸': 3074, '裹': 3075, '裾': 3076, '褐': 3077, '褒': 3078, '褚': 3079, '褥': 3080, '襄': 3081, '襟': 3082, '西': 3083, '要': 3084, '覆': 3085, '覈': 3086, '见': 3087, '观': 3088, '规': 3089, '觅': 3090, '视': 3091, '览': 3092, '觉': 3093, '觐': 3094, '觑': 3095, '角': 3096, '觜': 3097, '觞': 3098, '解': 3099, '觥': 3100, '触': 3101, '觫': 3102, '觳': 3103, '言': 3104, '誉': 3105, '誓': 3106, '譔': 3107, '警': 3108, '譬': 3109, '计': 3110, '订': 3111, '讣': 3112, '认': 3113, '讥': 3114, '讨': 3115, '让': 3116, '讪': 3117, '讫': 3118, '训': 3119, '议': 3120, '讯': 3121, '记': 3122, '讲': 3123, '讳': 3124, '讴': 3125, '讶': 3126, '许': 3127, '讹': 3128, '论': 3129, '讼': 3130, '讽': 3131, '设': 3132, '访': 3133, '诀': 3134, '证': 3135, '评': 3136, '识': 3137, '诈': 3138, '诉': 3139, '诊': 3140, '诌': 3141, '词': 3142, '诏': 3143, '试': 3144, '诗': 3145, '诘': 3146, '诚': 3147, '诛': 3148, '话': 3149, '诞': 3150, '诠': 3151, '诡': 3152, '询': 3153, '诣': 3154, '诤': 3155, '该': 3156, '详': 3157, '诩': 3158, '诫': 3159, '诬': 3160, '语': 3161, '误': 3162, '诰': 3163, '诱': 3164, '诲': 3165, '诳': 3166, '说': 3167, '诵': 3168, '请': 3169, '诸': 3170, '诹': 3171, '诺': 3172, '读': 3173, '课': 3174, '谀': 3175, '谁': 3176, '调': 3177, '谄': 3178, '谅': 3179, '谈': 3180, '谊': 3181, '谋': 3182, '谌': 3183, '谍': 3184, '谏': 3185, '谐': 3186, '谑': 3187, '谒': 3188, '谓': 3189, '谕': 3190, '谗': 3191, '谘': 3192, '谙': 3193, '谚': 3194, '谛': 3195, '谞': 3196, '谡': 3197, '谢': 3198, '谣': 3199, '谤': 3200, '谥': 3201, '谦': 3202, '谧': 3203, '谨': 3204, '谪': 3205, '谬': 3206, '谭': 3207, '谮': 3208, '谯': 3209, '谱': 3210, '谲': 3211, '谴': 3212, '谶': 3213, '谷': 3214, '豁': 3215, '豆': 3216, '豕': 3217, '豚': 3218, '象': 3219, '豨': 3220, '豪': 3221, '豫': 3222, '豸': 3223, '豹': 3224, '豺': 3225, '貂': 3226, '貅': 3227, '貌': 3228, '貔': 3229, '賨': 3230, '贝': 3231, '贞': 3232, '负': 3233, '贡': 3234, '财': 3235, '责': 3236, '贤': 3237, '败': 3238, '货': 3239, '质': 3240, '贩': 3241, '贪': 3242, '贫': 3243, '贬': 3244, '购': 3245, '贮': 3246, '贯': 3247, '贰': 3248, '贱': 3249, '贲': 3250, '贴': 3251, '贵': 3252, '费': 3253, '贺': 3254, '贻': 3255, '贼': 3256, '贽': 3257, '贾': 3258, '贿': 3259, '赀': 3260, '赂': 3261, '赃': 3262, '资': 3263, '赈': 3264, '赋': 3265, '赌': 3266, '赍': 3267, '赎': 3268, '赏': 3269, '赐': 3270, '赖': 3271, '赘': 3272, '赚': 3273, '赛': 3274, '赞': 3275, '赠': 3276, '赡': 3277, '赢': 3278, '赤': 3279, '赦': 3280, '赧': 3281, '赫': 3282, '赭': 3283, '走': 3284, '赴': 3285, '赵': 3286, '赶': 3287, '起': 3288, '趁': 3289, '超': 3290, '越': 3291, '趋': 3292, '趱': 3293, '足': 3294, '趷': 3295, '跃': 3296, '跄': 3297, '跋': 3298, '跌': 3299, '跎': 3300, '跑': 3301, '跖': 3302, '跛': 3303, '距': 3304, '跞': 3305, '跟': 3306, '跣': 3307, '跨': 3308, '跪': 3309, '路': 3310, '跳': 3311, '践': 3312, '跶': 3313, '跸': 3314, '跼': 3315, '踅': 3316, '踉': 3317, '踊': 3318, '踌': 3319, '踏': 3320, '踞': 3321, '踢': 3322, '踪': 3323, '踵': 3324, '蹄': 3325, '蹇': 3326, '蹈': 3327, '蹉': 3328, '蹊': 3329, '蹋': 3330, '蹐': 3331, '蹑': 3332, '蹙': 3333, '蹬': 3334, '蹶': 3335, '躁': 3336, '躄': 3337, '躇': 3338, '躔': 3339, '身': 3340, '躬': 3341, '躯': 3342, '躲': 3343, '轘': 3344, '车': 3345, '轨': 3346, '轩': 3347, '转': 3348, '轮': 3349, '软': 3350, '轰': 3351, '轲': 3352, '轴': 3353, '轵': 3354, '轸': 3355, '轻': 3356, '载': 3357, '轿': 3358, '辂': 3359, '较': 3360, '辄': 3361, '辅': 3362, '辆': 3363, '辇': 3364, '辈': 3365, '辉': 3366, '辍': 3367, '辎': 3368, '辑': 3369, '输': 3370, '辔': 3371, '辕': 3372, '辖': 3373, '辛': 3374, '辜': 3375, '辞': 3376, '辟': 3377, '辨': 3378, '辩': 3379, '辰': 3380, '辱': 3381, '边': 3382, '辽': 3383, '达': 3384, '迁': 3385, '迂': 3386, '迄': 3387, '迅': 3388, '过': 3389, '迈': 3390, '迎': 3391, '运': 3392, '近': 3393, '迓': 3394, '返': 3395, '还': 3396, '这': 3397, '进': 3398, '远': 3399, '违': 3400, '连': 3401, '迟': 3402, '迢': 3403, '迤': 3404, '迩': 3405, '迫': 3406, '迭': 3407, '述': 3408, '迷': 3409, '迸': 3410, '迹': 3411, '追': 3412, '退': 3413, '送': 3414, '适': 3415, '逃': 3416, '逅': 3417, '逆': 3418, '选': 3419, '逊': 3420, '逍': 3421, '透': 3422, '逐': 3423, '递': 3424, '途': 3425, '逗': 3426, '通': 3427, '逝': 3428, '逞': 3429, '速': 3430, '造': 3431, '逡': 3432, '逢': 3433, '逦': 3434, '逮': 3435, '逵': 3436, '逶': 3437, '逸': 3438, '逻': 3439, '逼': 3440, '逾': 3441, '遁': 3442, '遂': 3443, '遇': 3444, '遍': 3445, '遏': 3446, '遐': 3447, '遑': 3448, '道': 3449, '遗': 3450, '遣': 3451, '遥': 3452, '遨': 3453, '遭': 3454, '遮': 3455, '遵': 3456, '遽': 3457, '避': 3458, '邀': 3459, '邂': 3460, '邈': 3461, '邑': 3462, '邓': 3463, '邕': 3464, '邙': 3465, '邢': 3466, '那': 3467, '邦': 3468, '邪': 3469, '邮': 3470, '邯': 3471, '邰': 3472, '邱': 3473, '邳': 3474, '邴': 3475, '邵': 3476, '邸': 3477, '邹': 3478, '邺': 3479, '邻': 3480, '邽': 3481, '邾': 3482, '郁': 3483, '郃': 3484, '郊': 3485, '郎': 3486, '郏': 3487, '郑': 3488, '郗': 3489, '郝': 3490, '郡': 3491, '郢': 3492, '郤': 3493, '郦': 3494, '部': 3495, '郭': 3496, '郯': 3497, '郸': 3498, '都': 3499, '郿': 3500, '鄂': 3501, '鄄': 3502, '鄙': 3503, '鄠': 3504, '鄢': 3505, '鄣': 3506, '鄱': 3507, '酂': 3508, '酉': 3509, '酋': 3510, '酌': 3511, '配': 3512, '酎': 3513, '酒': 3514, '酗': 3515, '酣': 3516, '酥': 3517, '酬': 3518, '酱': 3519, '酷': 3520, '酸': 3521, '酹': 3522, '酾': 3523, '酿': 3524, '醉': 3525, '醋': 3526, '醒': 3527, '醢': 3528, '醮': 3529, '醴': 3530, '采': 3531, '释': 3532, '里': 3533, '重': 3534, '野': 3535, '量': 3536, '金': 3537, '釜': 3538, '釭': 3539, '釿': 3540, '鈇': 3541, '鈚': 3542, '鉴': 3543, '銮': 3544, '鍪': 3545, '鏖': 3546, '钁': 3547, '针': 3548, '钉': 3549, '钓': 3550, '钗': 3551, '钝': 3552, '钟': 3553, '钢': 3554, '钦': 3555, '钧': 3556, '钩': 3557, '钱': 3558, '钳': 3559, '钵': 3560, '钺': 3561, '铁': 3562, '铃': 3563, '铜': 3564, '铠': 3565, '铨': 3566, '铭': 3567, '铮': 3568, '银': 3569, '铸': 3570, '铺': 3571, '链': 3572, '销': 3573, '锁': 3574, '锄': 3575, '锅': 3576, '锋': 3577, '锐': 3578, '错': 3579, '锡': 3580, '锢': 3581, '锣': 3582, '锤': 3583, '锥': 3584, '锦': 3585, '锭': 3586, '键': 3587, '锯': 3588, '锵': 3589, '锹': 3590, '镇': 3591, '镌': 3592, '镔': 3593, '镜': 3594, '镝': 3595, '镫': 3596, '镬': 3597, '镰': 3598, '镶': 3599, '长': 3600, '闇': 3601, '门': 3602, '闪': 3603, '闭': 3604, '问': 3605, '闲': 3606, '间': 3607, '闵': 3608, '闷': 3609, '闸': 3610, '闹': 3611, '闺': 3612, '闻': 3613, '闼': 3614, '闾': 3615, '闿': 3616, '阁': 3617, '阃': 3618, '阄': 3619, '阅': 3620, '阆': 3621, '阉': 3622, '阊': 3623, '阍': 3624, '阎': 3625, '阐': 3626, '阑': 3627, '阔': 3628, '阖': 3629, '阙': 3630, '阚': 3631, '阜': 3632, '队': 3633, '阡': 3634, '阪': 3635, '阱': 3636, '防': 3637, '阳': 3638, '阴': 3639, '阵': 3640, '阶': 3641, '阻': 3642, '阿': 3643, '陂': 3644, '附': 3645, '际': 3646, '陆': 3647, '陇': 3648, '陈': 3649, '陋': 3650, '陌': 3651, '降': 3652, '限': 3653, '陕': 3654, '陛': 3655, '陟': 3656, '院': 3657, '除': 3658, '陨': 3659, '险': 3660, '陪': 3661, '陵': 3662, '陶': 3663, '陷': 3664, '隅': 3665, '隆': 3666, '隈': 3667, '随': 3668, '隐': 3669, '隔': 3670, '隗': 3671, '隘': 3672, '隙': 3673, '障': 3674, '隧': 3675, '隰': 3676, '隳': 3677, '隶': 3678, '隽': 3679, '难': 3680, '雀': 3681, '雁': 3682, '雄': 3683, '雅': 3684, '集': 3685, '雉': 3686, '雌': 3687, '雍': 3688, '雏': 3689, '雒': 3690, '雕': 3691, '雝': 3692, '雠': 3693, '雨': 3694, '雪': 3695, '雳': 3696, '零': 3697, '雷': 3698, '雹': 3699, '雾': 3700, '需': 3701, '霁': 3702, '霄': 3703, '霆': 3704, '震': 3705, '霍': 3706, '霎': 3707, '霏': 3708, '霖': 3709, '霜': 3710, '霞': 3711, '露': 3712, '霸': 3713, '霹': 3714, '青': 3715, '靓': 3716, '靖': 3717, '静': 3718, '非': 3719, '靠': 3720, '靡': 3721, '面': 3722, '革': 3723, '靬': 3724, '靳': 3725, '靴': 3726, '靶': 3727, '鞅': 3728, '鞍': 3729, '鞒': 3730, '鞘': 3731, '鞠': 3732, '鞦': 3733, '鞭': 3734, '韦': 3735, '韧': 3736, '韩': 3737, '韪': 3738, '韬': 3739, '音': 3740, '韵': 3741, '韶': 3742, '顒': 3743, '顗': 3744, '顶': 3745, '顷': 3746, '项': 3747, '顺': 3748, '须': 3749, '顽': 3750, '顾': 3751, '顿': 3752, '颀': 3753, '颂': 3754, '预': 3755, '颅': 3756, '领': 3757, '颇': 3758, '颈': 3759, '颊': 3760, '颌': 3761, '颍': 3762, '颐': 3763, '频': 3764, '颓': 3765, '颔': 3766, '颖': 3767, '颗': 3768, '题': 3769, '颜': 3770, '额': 3771, '颠': 3772, '颤': 3773, '风': 3774, '飏': 3775, '飐': 3776, '飘': 3777, '飙': 3778, '飞': 3779, '食': 3780, '飨': 3781, '餐': 3782, '餮': 3783, '饕': 3784, '饥': 3785, '饬': 3786, '饭': 3787, '饮': 3788, '饯': 3789, '饰': 3790, '饱': 3791, '饵': 3792, '饶': 3793, '饷': 3794, '饼': 3795, '饿': 3796, '馀': 3797, '馁': 3798, '馆': 3799, '馈': 3800, '馑': 3801, '馒': 3802, '馔': 3803, '首': 3804, '馗': 3805, '馘': 3806, '香': 3807, '馥': 3808, '馨': 3809, '騕': 3810, '马': 3811, '驭': 3812, '驮': 3813, '驯': 3814, '驰': 3815, '驱': 3816, '驴': 3817, '驷': 3818, '驸': 3819, '驹': 3820, '驻': 3821, '驼': 3822, '驽': 3823, '驾': 3824, '驿': 3825, '骁': 3826, '骂': 3827, '骄': 3828, '骅': 3829, '骆': 3830, '骇': 3831, '骈': 3832, '骋': 3833, '验': 3834, '骏': 3835, '骑': 3836, '骖': 3837, '骘': 3838, '骚': 3839, '骝': 3840, '骞': 3841, '骠': 3842, '骡': 3843, '骤': 3844, '骥': 3845, '骧': 3846, '骨': 3847, '骸': 3848, '髀': 3849, '髓': 3850, '高': 3851, '髡': 3852, '髦': 3853, '髫': 3854, '髭': 3855, '髯': 3856, '髻': 3857, '鬃': 3858, '鬅': 3859, '鬓': 3860, '鬯': 3861, '鬻': 3862, '鬼': 3863, '魁': 3864, '魂': 3865, '魄': 3866, '魅': 3867, '魇': 3868, '魏': 3869, '鱼': 3870, '鲁': 3871, '鲂': 3872, '鲈': 3873, '鲍': 3874, '鲜': 3875, '鲧': 3876, '鲲': 3877, '鲵': 3878, '鲸': 3879, '鳅': 3880, '鳌': 3881, '鳖': 3882, '鳝': 3883, '鳞': 3884, '鸟': 3885, '鸠': 3886, '鸡': 3887, '鸣': 3888, '鸦': 3889, '鸩': 3890, '鸭': 3891, '鸯': 3892, '鸳': 3893, '鸷': 3894, '鸾': 3895, '鸿': 3896, '鹄': 3897, '鹅': 3898, '鹉': 3899, '鹊': 3900, '鹏': 3901, '鹗': 3902, '鹤': 3903, '鹦': 3904, '鹩': 3905, '鹪': 3906, '鹭': 3907, '鹰': 3908, '鹿': 3909, '麈': 3910, '麋': 3911, '麒': 3912, '麟': 3913, '麦': 3914, '麴': 3915, '麻': 3916, '麾': 3917, '黄': 3918, '黍': 3919, '黎': 3920, '黑': 3921, '默': 3922, '黛': 3923, '黜': 3924, '黥': 3925, '黩': 3926, '黯': 3927, '鼎': 3928, '鼐': 3929, '鼓': 3930, '鼕': 3931, '鼙': 3932, '鼠': 3933, '鼻': 3934, '齁': 3935, '齐': 3936, '齑': 3937, '齿': 3938, '龄': 3939, '龙': 3940, '龚': 3941, '龛': 3942, '龟': 3943, '！': 3944, '（': 3945, '）': 3946, '，': 3947, '：': 3948, '；': 3949, '？': 3950}\n"
     ]
    }
   ],
   "source": [
    "dataset = CharDataset(text, seq_len)\n",
    "vocab_size = len(dataset.chars)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model = TransformerDecoder(embed_size, heads, forward_expansion, DROPOUT, vocab_size, decoder_layers, max_position_embeddings)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(f\"vocab size: {vocab_size}\")\n",
    "print(f\"embedding lookup table: {dataset.char_to_index}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T15:47:05.787225Z",
     "start_time": "2024-07-25T15:47:05.676481Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练之前的准备\n",
    "\n",
    "- 创建mask：在训练的时候，我们希望输出第i个位置时，注意力分数在i,i+1,...的位置都是0\n",
    "- 训练函数：两层for循环，每次输入的inputs是str2idx后的一个数字组成的矩阵[B, T]，在模型侧进行embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
    "    # mask = torch.zeros(size, size) \n",
    "    return mask \n",
    "\n",
    "\n",
    "def train(dataloader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    for epoch in range(EPOCH):\n",
    "        for inputs, targets in tqdm(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            mask = create_look_ahead_mask(inputs.size(1)).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs, mask) \n",
    "            loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
    "            if(step % 10 == 1):\n",
    "                print(f\"Epoch {epoch} step {step}, Loss: {loss.item()}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "\n",
    "def generate_sequence_topk(model, start_sequence, length, dataset, device, k=5):\n",
    "    model.eval()\n",
    "    generated_sequence = start_sequence\n",
    "\n",
    "    # 将初始序列转换为索引\n",
    "    inputs = torch.tensor([dataset.char_to_index[ch] for ch in start_sequence], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    # 在推理时不计算梯度\n",
    "    with torch.no_grad(): \n",
    "        for _ in range(length):\n",
    "            mask = create_look_ahead_mask(inputs.size(dim=1))\n",
    "            output = model(inputs, mask)\n",
    "            # [B, T, C]，只关心最后一个token\n",
    "            last_output = output[:, -1, :]\n",
    "            probabilities = F.softmax(last_output, dim=1)\n",
    "            top_probabilities, top_indices = torch.topk(probabilities, k, dim=1)\n",
    "            top_prob_distribution = torch.distributions.Categorical(top_probabilities)\n",
    "            chosen_index = top_indices[0][top_prob_distribution.sample()].item()\n",
    "            generated_sequence += dataset.index_to_char[chosen_index]\n",
    "            inputs = torch.cat([inputs, torch.tensor([[chosen_index]], device=device)], dim=1)\n",
    "\n",
    "    return generated_sequence\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T16:04:16.628562Z",
     "start_time": "2024-07-25T16:04:16.617152Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/75597 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d0e7455ecf5475096f4a7977648b064"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 step 1, Loss: 4.170106410980225\n",
      "Epoch 0 step 11, Loss: 4.059938430786133\n",
      "Epoch 0 step 21, Loss: 3.8189704418182373\n",
      "Epoch 0 step 31, Loss: 4.006127834320068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[36], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(dataloader, model, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m     13\u001B[0m mask \u001B[38;5;241m=\u001B[39m create_look_ahead_mask(inputs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 15\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m \n\u001B[1;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, vocab_size), targets\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(step \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[13], line 108\u001B[0m, in \u001B[0;36mTransformerDecoder.forward\u001B[0;34m(self, x, src_mask)\u001B[0m\n\u001B[1;32m    106\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_encoding(x)\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m--> 108\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc_out(x)\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[13], line 86\u001B[0m, in \u001B[0;36mTransformerDecoderLayer.forward\u001B[0;34m(self, x, src_mask)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, src_mask):\n\u001B[0;32m---> 86\u001B[0m     attn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(attn_out \u001B[38;5;241m+\u001B[39m x))\n\u001B[1;32m     88\u001B[0m     forward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeed_forward(x)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[13], line 68\u001B[0m, in \u001B[0;36mMultiHeadAttention.forward\u001B[0;34m(self, value, key, query, mask)\u001B[0m\n\u001B[1;32m     66\u001B[0m out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(attention, values_t)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(B, value_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# [B, T, C]\u001B[39;00m\n\u001B[0;32m---> 68\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(dataloader, model, optimizer, criterion, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T16:04:22.204311Z",
     "start_time": "2024-07-25T16:04:17.548641Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T06:02:23.929696Z",
     "start_time": "2024-07-25T06:02:23.921342Z"
    }
   },
   "execution_count": 207
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用刚才训练的模型进行推理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-k 输出:\n",
      " 玄德与孔明同宗亲，请玄德与玄德同宗族，不可。”玄德曰：“吾与玄德同宗族，不可轻敌。”玄德曰：“吾与我同谋，何故不相见？”孔明曰：“吾与我同谋，何故不相见。”玄德曰：“吾与玄德同谋，不可轻敌。”玄德曰：“吾与汝等\n"
     ]
    }
   ],
   "source": [
    "start_sequence = \"玄德与孔明\"\n",
    "generated_length = 100\n",
    "k = 1\n",
    "generated_sequence = generate_sequence_topk(model, start_sequence, generated_length, dataset, device, k)\n",
    "print(f\"top-k 输出:\\n {generated_sequence}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T16:04:32.292230Z",
     "start_time": "2024-07-25T16:04:31.998218Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T06:02:03.989121Z",
     "start_time": "2024-07-25T06:02:03.985879Z"
    }
   },
   "execution_count": 197
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型参数展示：\n",
    "FYI：\n",
    "- 一个相对有用的GPT模型：GPT3：175B + 580GB data\n",
    "- 主流大模型：7B, 13B, 33B, 70B  + 2～20TB data\n",
    "- 常见的chatbot & 垂直领域大模型：33B / 70B  + 2～20TB data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "# Calculate the total number of trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {trainable_params}\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 交叉熵误差\n",
    "\n",
    "- 预测值（概率）：[0.7, 0.2, 0.1]\n",
    "- 真实值：0\n",
    "- 真实值（概率）：[1, 0, 0]\n",
    "- CEL: -[ 1 * log(0.7) + 0 * log(0.2) + 0 * log(0.1) ] = -log(0.7) ~ 0.36\n",
    "\n",
    "但目标预测下，真实值是一个one-hot vector，\n",
    "- 瞎猜（现在词表大小约20，平均下来概率为5%）：-log(0.05) ~ 2.99\n",
    "- 假设某个大模型词表100k，每个词概率1e-5：-log(1e-5) ~ 11.5 （大模型初始误差，经过训练收敛后大概在1～2左右）\n",
    "- 20%（有20%概率预测正确）：-log(0.2) ~ 1.61\n",
    "- 50%（有50%概率预测正确）：-log(0.5) ~ 0.69\n",
    "- 80% (有80%概率预测正确)：-log(0.8) ~ 0.22"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 10., -20., -20., -20.],\n",
      "         [ 10., -20., -20., -20.],\n",
      "         [ 10., -20., -20., -20.]],\n",
      "\n",
      "        [[ 10., -20., -20., -20.],\n",
      "         [ 10., -20., -20., -20.],\n",
      "         [ 10., -20., -20., -20.]]])\n",
      "torch.Size([2, 3, 4])\n",
      "Logits (flattened): \n",
      "tensor([[ 10., -20., -20., -20.],\n",
      "        [ 10., -20., -20., -20.],\n",
      "        [ 10., -20., -20., -20.],\n",
      "        [ 10., -20., -20., -20.],\n",
      "        [ 10., -20., -20., -20.],\n",
      "        [ 10., -20., -20., -20.]])\n",
      "Targets (flattened): \n",
      "tensor([0, 0, 0, 0, 0, 0])\n",
      "Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "vocab_size = 4\n",
    "\n",
    "logits = torch.tensor([[[10, -20, -20, -20], [10, -20, -20, -20], [10, -20, -20, -20]],\n",
    "                       [[10, -20, -20, -20], [10, -20, -20, -20], [10, -20, -20, -20]]], dtype=torch.float32)\n",
    "# logits = torch.tensor([[[1,0,0,0], [1,0,0,0], [1,0,0,0]],[[1,0,0,0], [1,0,0,0], [1,0,0,0]]], dtype=torch.float32)\n",
    "print(logits)\n",
    "print(logits.shape)\n",
    "\n",
    "targets = torch.tensor([[0,0,0], [0,0,0]], dtype=torch.long)\n",
    "\n",
    "logits_flattened = logits.view(-1, vocab_size)\n",
    "targets_flattened = targets.view(-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits_flattened, targets_flattened)\n",
    "\n",
    "print(f\"Logits (flattened): \\n{logits_flattened}\")\n",
    "print(f\"Targets (flattened): \\n{targets_flattened}\")\n",
    "print(f\"Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T08:40:39.952968Z",
     "start_time": "2024-07-25T08:40:39.943313Z"
    }
   },
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 大模型推理优化\n",
    "- 训练时可以使用mask来进行并行训练\n",
    "- 输出的时候是：auto regressive，不可能并行，如何加快？\n",
    "\n",
    "### KV cache\n",
    "回顾我们刚才的实现：每次推理的时候都需要调用模型进行完整的计算，包括：\n",
    "1. input乘以3个矩阵得到k,q,v（实际上我们只需要前t-1个词的k和v，以及最后一个词的q）\n",
    "2. 进行前向传播\n",
    "\n",
    "### 其他策略\n",
    "1. 量化处理，int4 int8量化有望在手机上实现大模型部署， （FP32)7B -> 28GB   （int8)7B -> 7GB\n",
    "2. kernel fusion & 高性能算子：flashAttention\n",
    "3. 更合理的模型结构：MOE，增加参数量，但是推理的时候参数量不变\n",
    "4. 流式现实：提高用户体验-_-!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "length = None\n",
    "input = None\n",
    "for _ in range(length):\n",
    "    mask = create_look_ahead_mask(inputs.size(dim=1))\n",
    "    # 调用模型\n",
    "    output = model(inputs, mask)\n",
    "    # [B, T, C]，只关心最后一个token\n",
    "    last_output = output[:, -1, :]\n",
    "    # 拿到概率然后转换成char\n",
    "    probabilities = F.softmax(last_output, dim=1)\n",
    "    top_probabilities, top_indices = torch.topk(probabilities, k, dim=1)\n",
    "    top_prob_distribution = torch.distributions.Categorical(top_probabilities)\n",
    "    chosen_index = top_indices[0][top_prob_distribution.sample()].item()\n",
    "    # 放入seq作为输入\n",
    "    generated_sequence += dataset.index_to_char[chosen_index]\n",
    "    inputs = torch.cat([inputs, torch.tensor([[chosen_index]], device=device)], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_nmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
